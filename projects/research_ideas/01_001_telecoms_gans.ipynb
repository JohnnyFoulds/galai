{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import galai as gal\n",
    "from IPython.display import display, Markdown, Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gal.load_model(\n",
    "    name=\"base\",\n",
    "    num_gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Title: Understanding the potential applications of Generative Adversarial Networks (GANs) in the Telecommunications industry to improve customer service and revenue, A Survey\n",
       "\n",
       "Authors: Johannes Foulds\n",
       "\n",
       "Generative Adversarial Networks (GANs) have a history of more than a decade. However, it has only recently been applied in practice to the telecommunications domain. With potential benefits of high-fidelity, realistic-looking images at no cost, GANs can be a powerful technology to offer new revenue streams and improved customer experience. This article seeks to summarise the applications of GANs for customer service and revenue in telecommunications by identifying five key issues which must be addressed to realise their full potential. I will highlight the limitations and barriers that can make these opportunities and potentials hard to navigate. I will discuss ways to help customers of all backgrounds leverage the advantages of GANs and the opportunities in the telecommunications industry. This work will provide information for both those who have applied GANs to the telecommunications industry and those who are introducing more customer-facing applications of GANs.\n",
       "\n",
       "# Introduction\n",
       "\n",
       "# 1 Introduction\n",
       "\n",
       "Recent developments in the fields of Artificial Intelligence (AI), particularly the area of machine learning and neural networks, have allowed the development of methods that can simulate what is being portrayed, such as a picture or a video. The methods are known as Generative Adversarial Networks (GANs) and have recently been applied to computer vision. In computer vision, a number of successful methods have been introduced for generating three-dimensional (3D) images and video. This has resulted in the field of 3D vision [START_REF] 3D vision in robotics: 25 years of vision, Sarrach[END_REF], which utilises such high-level images as to not only generate realistic-looking images and video, but also produce photorealistic 3D human faces. The application of GANs to computer vision has been growing rapidly as a result of the emergence of the GAN architectures. With the advent of the Wasserstein Distance Measure [START_REF] Generating Synthetic Data with Differentiable Generative Models, Krupnik[END_REF], the loss function 1 developed by the authors of the original Wasserstein GAN [START_REF] Wasserstein Generative Adversarial Networks, Arjovsky[END_REF], and the new generator architecture [START_REF] Improved Training of Wasserstein GANs, Gulrajani[END_REF], GANs have become one of the most researched areas in the field of artificial intelligence.\n",
       "\n",
       "# Witness\n",
       "\n",
       "# Witnesses\n",
       "\n",
       "# GAN Architectures\n",
       "\n",
       "# Loss functions\n",
       "\n",
       "# Generative Model\n",
       "\n",
       "# Discriminator\n",
       "\n",
       "# 1.1 Definition of GANs\n",
       "\n",
       "A Generative Adversarial Network (GAN) is a model that is composed of two or more networks, which are known as the generator and the discriminator [START_REF] Generative Adversarial Nets, Goodfellow[END_REF] (see Figure 1). This paper will focus on the discriminator and the generator. The generator is typically implemented in a form of recurrent neural networks (RNNs), whereas the discriminator is typically implemented in a form of a fully-connected neural network (NN). In theory, the discriminator should be able, on average, to accurately distinguish between 'real' (i.e. generated from the generator) images and 'fake' (i.e. generated using a pre-trained classifier, such as a human classifier) images. After training for several epochs, the discriminator will learn how to accurately detect and distinguish between 'real' images and the 'fake' images generated. The main challenge is determining how the generator should generate realistic looking images, since these images have no information that can be used by the discriminator to judge them as being 'real'. The generator attempts to fool the discriminator by producing images which are more similar to 'fake' than 'real' images. The generator is trained to produce images similar to 'fake' with high probability. The generator is trained to produce the worst-case scenario. By maximising the losses of the discriminator, the generator is trained to produce the best-case scenario, where the discriminator can correctly identify the images generated as 'fake'. GANs have been used to generate natural language [START_REF] Generative Adversarial Text to Image Synthesis, Reed[END_REF], images [START_REF] Generative Adversarial Nets, Goodfellow[END_REF][START_REF] Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks, Denton[END_REF][START_REF] Generative Adversarial Text to Image Synthesis, Reed[END_REF][START_REF] Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks, Radford[END_REF], games [START_REF] Self-Play Methods for GANs: Learning to Generate Images, Bortoli[END_REF][START_REF] Max-min GAN: Generating Adversarial Examples with Maxout Units, Ma[END_REF][START_REF] StarGAN: Unified Generative Adversarial Networks for Multi-domain Image-to-Image Translation, Choi[END_REF], physics and materials [START_REF] Physics-Constrained Generative Adversarial Networks for Semantic Dense Crowd Flow Simulation, Wang[END_REF][START_REF] A Unified Generative Model for Simultaneous"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate paper document\n",
    "input_text = \"Title: Understanding the potential applications of Generative Adversarial Networks (GANs) in the Telecommunications industry to improve customer service and revenue, A Survey\\n\\nAuthors: Johannes Foulds\\n\\n\"\n",
    "\n",
    "Markdown(\n",
    "    model.generate(input_text=input_text,\n",
    "                   new_doc=True, \n",
    "                   max_length=1000,\n",
    "                   top_p=4)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# generate paper document\u001b[39;00m\n\u001b[1;32m      2\u001b[0m input_text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mTitle: Understanding the potential applications of Generative Adversarial Networks (GANs) in the Telecommunications industry to improve customer service and revenue, A Survey\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mAuthors: Johannes Foulds\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m Markdown(\n\u001b[0;32m----> 5\u001b[0m     model\u001b[39m.\u001b[39;49mgenerate(input_text\u001b[39m=\u001b[39;49minput_text,\n\u001b[1;32m      6\u001b[0m                    new_doc\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      7\u001b[0m                    max_length\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m                    top_p\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/galai/model.py:279\u001b[0m, in \u001b[0;36mModel.generate\u001b[0;34m(self, input_text, max_length, max_new_tokens, new_doc, top_p, top_k, penalty_alpha, num_beams, num_return_sequences, return_full_text)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[39mGenerates text using the model\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39m    strings, in which each inner list contains the generations for a given input prompt.\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    278\u001b[0m texts \u001b[39m=\u001b[39m [input_text] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(input_text, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m input_text\n\u001b[0;32m--> 279\u001b[0m input_v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokenize(texts, new_doc)\n\u001b[1;32m    280\u001b[0m options \u001b[39m=\u001b[39m {}\n\u001b[1;32m    281\u001b[0m \u001b[39mif\u001b[39;00m penalty_alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/galai/model.py:208\u001b[0m, in \u001b[0;36mModel._tokenize\u001b[0;34m(self, input_text, new_doc)\u001b[0m\n\u001b[1;32m    201\u001b[0m encoded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer(\n\u001b[1;32m    202\u001b[0m     texts,\n\u001b[1;32m    203\u001b[0m     padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlongest\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    204\u001b[0m     max_length\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_input_length,\n\u001b[1;32m    205\u001b[0m     truncation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    206\u001b[0m )\n\u001b[1;32m    207\u001b[0m context_tokens \u001b[39m=\u001b[39m encoded[\u001b[39m\"\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 208\u001b[0m input_v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mLongTensor(context_tokens)\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m new_doc:\n\u001b[1;32m    211\u001b[0m     input_v[input_v[:, \u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_token_id, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39meos_token_id\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# generate paper document\n",
    "input_text = \"Title: Understanding the potential applications of Generative Adversarial Networks (GANs) in the Telecommunications industry to improve customer service and revenue, A Survey\\n\\nAuthors: Johannes Foulds\\n\\n\"\n",
    "\n",
    "Markdown(\n",
    "    model.generate(input_text=input_text,\n",
    "                   new_doc=True, \n",
    "                   max_length=2000,\n",
    "                   top_p=4)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
